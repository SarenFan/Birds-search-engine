# HÆ¯á»šNG DáºªN CHáº Y CRAWLER TRÃŠN LIGHTNING.AI

## ğŸ¯ QUAN TRá»ŒNG: Lightning.ai ÄÃƒ THAY Äá»”I ARCHITECTURE!

**Lightning.ai hiá»‡n táº¡i (2026) khÃ´ng cÃ²n há»— trá»£ CLI Jobs nhÆ° trÆ°á»›c.**

Thay vÃ o Ä‘Ã³, báº¡n pháº£i dÃ¹ng **Lightning Studios** qua Web UI Ä‘á»ƒ cháº¡y background jobs.

---

## âœ… CÃCH CHáº Y ÄÃšNG: QUA LIGHTNING STUDIOS

### BÆ°á»›c 1: Táº¡o Lightning.ai Account

1. VÃ o https://lightning.ai
2. Sign up (verify email/phone)
3. Check credits: Báº¡n cÃ³ **22 credits** sáºµn

### BÆ°á»›c 2: Táº¡o Studio (Miá»…n phÃ­!)

1. Click **"New Studio"**
2. Chá»n: **CPU Studio** (4 cores - FREE)
3. Name: `seg301-crawler`
4. Wait ~30-60s Ä‘á»ƒ Studio khá»Ÿi Ä‘á»™ng

### BÆ°á»›c 3: Setup Environment trong Studio

**Má»Ÿ Terminal trong Studio** vÃ  cháº¡y:

```bash
# 1. Install system dependencies
sudo apt-get update
sudo apt-get install -y chromium-browser chromium-chromedriver

# 2. Clone repository
cd ~
git clone https://github.com/SarenFan/Birds-search-engine.git
cd Birds-search-engine

# 3. Install Python packages
pip install -r requirements.txt

# 4. Verify ChromeDriver
which chromedriver
# Should output: /usr/bin/chromedriver
```

### BÆ°á»›c 4: Enable Background Execution

**Cá»°C Ká»² QUAN TRá»ŒNG Ä‘á»ƒ crawler khÃ´ng dá»«ng khi Ä‘Ã³ng tab!**

1. Click **Settings** (âš™ï¸ icon) trong Studio
2. TÃ¬m **"Background Execution"**
3. Toggle ON (báº­t)
4. Save settings

### BÆ°á»›c 5: Run Crawler Background

```bash
# Trong Studio terminal

# Option 1: Sequential Mode (An toÃ n, á»•n Ä‘á»‹nh)
nohup python3 lightning_job_crawler.py --mode sequential > crawler.log 2>&1 &

# Option 2: Parallel Mode (Nhanh hÆ¡n, cáº§n nhiá»u tÃ i nguyÃªn)
nohup python3 lightning_job_crawler.py --mode parallel --workers 2 > crawler.log 2>&1 &

# Check process Ä‘ang cháº¡y
ps aux | grep lightning_job_crawler

# Follow logs
tail -f crawler.log
```

### BÆ°á»›c 6: ÄÃ“NG BROWSER - Crawler váº«n cháº¡y ngáº§m!

âœ… BÃ¢y giá» báº¡n cÃ³ thá»ƒ:

- ÄÃ³ng tab browser
- Táº¯t mÃ¡y tÃ­nh
- Äi ngá»§
- Crawler váº«n cháº¡y 24/7 trÃªn Lightning.ai!

### BÆ°á»›c 7: Check Progress (Báº¥t cá»© lÃºc nÃ o)

```bash
# Reopen Studio tá»« https://lightning.ai/studios
# Click vÃ o "seg301-crawler"
# Open terminal

# Check crawler status
ps aux | grep lightning_job_crawler

# Check logs
tail -100 crawler.log

# Check progress tá»« checkpoints
cat /tmp/lightning_artifacts/checkpoints/*.json

# Example output:
# voz_checkpoint.json: {"docs_collected": 125430, "last_page": 567}
# tinhte_checkpoint.json: {"docs_collected": 89234, "last_page": 412}

# Check data size
du -sh /tmp/lightning_artifacts/data/*.jsonl
```

### BÆ°á»›c 8: Download Data khi xong

**Option 1: Via Studio UI (Dá»… nháº¥t)**

```bash
# Compress data
cd /tmp/lightning_artifacts/data
tar -czf seg301_data.tar.gz *.jsonl

# Download:
# - Click vÃ o file seg301_data.tar.gz trong Studio file browser
# - Right click â†’ Download
```

**Option 2: Via Lightning Drive (Cho data lá»›n)**

```bash
# Copy to shared Lightning Drive
cp /tmp/lightning_artifacts/data/*.jsonl ~/lightning_drive/

# Sau Ä‘Ã³ download tá»« Lightning.ai dashboard â†’ Drive
```

---

## âš™ï¸ CONFIGURATION OPTIONS

### Sequential Mode (Khuyáº¿n nghá»‹ cho FREE Studio)

```bash
python3 lightning_job_crawler.py --mode sequential
```

**Æ¯u Ä‘iá»ƒm:**

- âœ… á»”n Ä‘á»‹nh, Ã­t lá»—i
- âœ… TiÃªu tá»‘n Ã­t RAM/CPU
- âœ… PhÃ¹ há»£p FREE 4-core Studio

**NhÆ°á»£c Ä‘iá»ƒm:**

- âš ï¸ Cháº­m hÆ¡n (cháº¡y láº§n lÆ°á»£t tá»«ng crawler)
- â±ï¸ Timeline: ~7-10 ngÃ y

### Parallel Mode (Cho Paid 8+ core Studio)

```bash
python3 lightning_job_crawler.py --mode parallel --workers 3
```

**Æ¯u Ä‘iá»ƒm:**

- âœ… Nhanh hÆ¡n (cháº¡y Ä‘á»“ng thá»i nhiá»u crawlers)
- â±ï¸ Timeline: ~5-7 ngÃ y vá»›i 8 cores

**NhÆ°á»£c Ä‘iá»ƒm:**

- âš ï¸ Cáº§n nhiá»u CPU/RAM
- ğŸ’° Tá»‘n credits náº¿u dÃ¹ng Paid Studio

---

## ğŸ’° CHI PHÃ Vá»šI 22 CREDITS

### Option 1: FREE Studio Only ($0)

```
Machine: 4 CPU cores (FREE 24/7)
Mode: Sequential
Timeline: 7-10 ngÃ y
Restart: Má»—i 4 giá» (checkpoint auto-resume)
Cost: $0
Result: 800K-1M docs
Remaining: 22 credits (giá»¯ nguyÃªn)
```

### Option 2: Hybrid (FREE + Paid 8-Core)

```
Week 1: FREE Studio
- Sequential mode
- 300-400K docs
- Cost: $0

Week 2: Upgrade to 8-Core Studio
- Parallel mode (3 workers)
- 600-700K docs
- Cost: ~$7-10 (72-100 giá» Ã— $0.10/giá»)

TOTAL:
- Timeline: 6-8 ngÃ y
- Result: 1M docs âœ“
- Cost: $7-10
- Remaining: $12-15 credits dá»± phÃ²ng
```

---

## ğŸ”„ HANDLE FREE STUDIO RESTART (Má»—i 4 giá»)

**FREE Studio tá»± Ä‘á»™ng restart sau 4 giá». ÄÃ¢y lÃ  cÃ¡ch handle:**

### Setup Auto-Resume Script

Táº¡o file `auto_resume.sh`:

```bash
#!/bin/bash
# Kiá»ƒm tra vÃ  restart crawler náº¿u bá»‹ dá»«ng

if ! pgrep -f "lightning_job_crawler.py" > /dev/null; then
    echo "âš¡ Restarting crawler..."
    cd ~/Birds-search-engine
    nohup python3 lightning_job_crawler.py --mode sequential > crawler.log 2>&1 &
    echo "âœ“ Crawler restarted at $(date)"
fi
```

**Make executable:**

```bash
chmod +x ~/auto_resume.sh
```

**Add to crontab (cháº¡y má»—i 5 phÃºt):**

```bash
crontab -e

# Add this line:
*/5 * * * * ~/auto_resume.sh >> ~/auto_resume.log 2>&1
```

Vá»›i setup nÃ y, crawler sáº½ tá»± Ä‘á»™ng resume trong vÃ²ng 5 phÃºt sau má»—i láº§n Studio restart!

---

## ğŸ“Š MONITORING

### Check Progress Real-time

```bash
# Watch checkpoint progress (update má»—i 60s)
watch -n 60 'cat /tmp/lightning_artifacts/checkpoints/*.json'

# Watch data size growth
watch -n 300 'du -sh /tmp/lightning_artifacts/data/*.jsonl'

# Watch crawler logs
tail -f crawler.log | grep -E "Collected|completed|ERROR"
```

### Summary Command

```bash
# Get full summary
python3 -c "
import json
from pathlib import Path

checkpoint_dir = Path('/tmp/lightning_artifacts/checkpoints')
total = 0

for f in checkpoint_dir.glob('*_checkpoint.json'):
    with open(f) as fp:
        data = json.load(fp)
        docs = data.get('docs_collected', 0)
        total += docs
        print(f'{f.stem}: {docs:,} docs')

print(f'TOTAL: {total:,} docs')
"
```

---

## âš ï¸ TROUBLESHOOTING

### Issue 1: Studio bá»‹ restart sau 4h

**Symptom:** Crawler dá»«ng, Studio bá»‹ sleep

**Solution:**

```bash
# Manual restart
cd ~/Birds-search-engine
nohup python3 lightning_job_crawler.py --mode sequential > crawler.log 2>&1 &

# Hoáº·c dÃ¹ng auto_resume.sh script (xem trÃªn)
```

### Issue 2: ChromeDriver not found

**Symptom:** `selenium.common.exceptions.WebDriverException`

**Solution:**

```bash
# Reinstall ChromeDriver
sudo apt-get update
sudo apt-get install -y chromium-browser chromium-chromedriver

# Verify
which chromedriver
chromedriver --version
```

### Issue 3: Out of disk space

**Symptom:** `No space left on device`

**Solution:**

```bash
# Check disk usage
df -h

# Compress old data
gzip /tmp/lightning_artifacts/data/*.jsonl

# Or download vÃ  xÃ³a data cÅ©
# (xem section Download Data)
```

### Issue 4: Crawler bá»‹ stuck

**Symptom:** Logs khÃ´ng update, process váº«n running

**Solution:**

```bash
# Kill stuck process
pkill -9 -f lightning_job_crawler

# Restart
cd ~/Birds-search-engine
nohup python3 lightning_job_crawler.py --mode sequential > crawler.log 2>&1 &

# Checkpoint sáº½ auto-resume tá»« nÆ¡i dá»«ng
```

---

## ğŸ“¥ DOWNLOAD DATA Vá»€ MÃY

### Method 1: Compress & Download (< 5GB)

```bash
# Trong Studio terminal
cd /tmp/lightning_artifacts/data

# Compress all data
tar -czf seg301_data.tar.gz *.jsonl

# Check size
ls -lh seg301_data.tar.gz

# Download:
# - Open Studio file browser
# - Navigate to /tmp/lightning_artifacts/data
# - Right-click seg301_data.tar.gz
# - Download
```

### Method 2: Lightning Drive (> 5GB)

```bash
# Copy to Lightning Drive
mkdir -p ~/lightning_drive/seg301_data
cp /tmp/lightning_artifacts/data/*.jsonl ~/lightning_drive/seg301_data/

# Download via dashboard:
# https://lightning.ai â†’ Drive â†’ seg301_data
```

### Method 3: Direct SCP (Fastest)

```bash
# Get Studio SSH info
# Settings â†’ SSH Access â†’ Copy SSH command

# On local machine:
scp -r <lightning-studio-ssh>:/tmp/lightning_artifacts/data/*.jsonl ./local/data/
```

---

## ğŸ¯ RECOMMENDED WORKFLOW

**Workflow tá»‘i Æ°u cho 22 credits:**

### Phase 1: Test Setup (Day 1)

```bash
# FREE Studio
# Test vá»›i sequential mode
# Cháº¡y 2-4 giá» Ä‘á»ƒ verify má»i thá»© hoáº¡t Ä‘á»™ng
# Check checkpoints, logs, data output
```

### Phase 2: Production Crawl (Day 2-8)

```bash
# FREE Studio
# Sequential mode 24/7
# Setup auto_resume.sh
# Monitor má»—i ngÃ y 1 láº§n
# Target: 800K-1M docs
# Cost: $0
```

### Phase 3: Optional Speedup (Náº¿u cáº§n)

```bash
# Náº¿u sau 5 ngÃ y chÆ°a Ä‘á»§ 1M docs:
# Upgrade to 8-Core Studio
# Parallel mode (3 workers)
# Run thÃªm 2-3 ngÃ y
# Cost: ~$5-7
```

### Phase 4: Download & Verify (Day 9)

```bash
# Compress data
# Download vá» mÃ¡y
# Verify doc count & data quality
# Delete Studio náº¿u khÃ´ng dÃ¹ng ná»¯a
```

---

## âœ… CHECKLIST TRÆ¯á»šC KHI Báº®T Äáº¦U

- [ ] Táº¡o Lightning.ai account
- [ ] Verify 22 credits cÃ³ sáºµn
- [ ] Táº¡o FREE CPU Studio
- [ ] Clone GitHub repository
- [ ] Install dependencies (chromium, requirements.txt)
- [ ] **Enable Background Execution** (QUAN TRá»ŒNG!)
- [ ] Test run crawler (5-10 phÃºt)
- [ ] Setup auto_resume.sh (cho Free tier)
- [ ] Start production crawl
- [ ] ÄÃ³ng browser - Ä‘i ngá»§ ğŸ˜´

---

## ğŸ“ SUPPORT & RESOURCES

**Lightning.ai:**

- Dashboard: https://lightning.ai
- Documentation: https://lightning.ai/docs
- Support: https://lightning.ai/discord

**Project:**

- GitHub: https://github.com/SarenFan/Birds-search-engine
- AI Log: PhanMinhTai_ai_log.md

**Script Files:**

- `lightning_job_crawler.py` - Main crawler manager
- `auto_resume.sh` - Auto-restart script
- `requirements.txt` - Python dependencies

---

**Created:** 2026-01-10
**Author:** Phan Minh Tai
**Status:** Ready for production deployment
**Estimated Timeline:** 6-10 days for 1M documents
**Estimated Cost:** $0-10 from 22 credits

ğŸš€ **READY TO START!**
